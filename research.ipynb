{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:17:11.273875Z",
     "start_time": "2024-08-05T02:17:10.172426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ],
   "id": "9e2d96d30c21dcb5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:17:11.745005Z",
     "start_time": "2024-08-05T02:17:11.274838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/krishnaik06/mlproject/main/notebook/data/stud.csv\")\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "cat_features = [feature for feature in X.columns if X[feature].dtype == 'O']\n",
    "num_features = [feature for feature in X.columns if feature not in cat_features]"
   ],
   "id": "70aeed0922fe14cf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:17:11.749456Z",
     "start_time": "2024-08-05T02:17:11.745909Z"
    }
   },
   "cell_type": "code",
   "source": "cat_features,num_features",
   "id": "484cf4413aba4171",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['gender',\n",
       "  'race_ethnicity',\n",
       "  'parental_level_of_education',\n",
       "  'lunch',\n",
       "  'test_preparation_course'],\n",
       " ['math_score', 'reading_score'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:17:11.756794Z",
     "start_time": "2024-08-05T02:17:11.750801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_encoder = StandardScaler()\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('OneHotEncoder', one_hot_encoder, cat_features),\n",
    "        ('StandardScaler', num_encoder, num_features)\n",
    "    ]\n",
    ")"
   ],
   "id": "e012769c478a314a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:17:11.763559Z",
     "start_time": "2024-08-05T02:17:11.757568Z"
    }
   },
   "cell_type": "code",
   "source": "X = preprocessor.fit_transform(X)",
   "id": "757db29f75f15db8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:17:11.766842Z",
     "start_time": "2024-08-05T02:17:11.764359Z"
    }
   },
   "cell_type": "code",
   "source": "X",
   "id": "4a5eddb706a35041",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.39002351,  0.19399858],\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.19207553,  1.42747598],\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         1.57771141,  1.77010859],\n",
       "       ...,\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "        -0.46775108,  0.12547206],\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.12609287,  0.60515772],\n",
       "       [ 1.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.71993682,  1.15336989]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "num_columns = X.shape[1]",
   "id": "a2f645f92b9f23cd",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X.shape",
   "id": "885f521ecfa379e4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)",
   "id": "5e45d794a73a4535",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class StudentDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.data = X\n",
    "        self.target_feature = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx].astype(np.float32)\n",
    "        y = self.target_feature.iloc[idx].astype(np.float32)\n",
    "        return torch.tensor(X), torch.tensor(y)\n",
    "    \n",
    "train_dataset = StudentDataset(X_train, y_train)\n",
    "test_dataset = StudentDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ],
   "id": "dae4d8ab62ad44d6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:43:24.989303Z",
     "start_time": "2024-08-05T02:43:24.987048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SingleLayerNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Linear(input_size, 128),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128, 1))\n",
    "        \n",
    "    \n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return self.fc1(x)"
   ],
   "id": "baa2c1efa59ded30",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:43:25.391515Z",
     "start_time": "2024-08-05T02:43:25.387905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'mps'\n",
    "model = SingleLayerNN(input_size=num_columns).to(device)"
   ],
   "id": "55a57c6adae719fe",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:43:25.734967Z",
     "start_time": "2024-08-05T02:43:25.732214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)"
   ],
   "id": "c2958dc94ac67e43",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:43:26.064866Z",
     "start_time": "2024-08-05T02:43:26.061902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(predictions, targets):\n",
    "    rmse = np.sqrt(mean_squared_error(targets, predictions))\n",
    "    r2 = r2_score(targets, predictions)\n",
    "    return rmse, r2"
   ],
   "id": "e78c02ee0408f23b",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T02:44:49.459795Z",
     "start_time": "2024-08-05T02:43:26.569445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    all_targets_train = []\n",
    "    all_predictions_train = []\n",
    "    model.train()\n",
    "    for _, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = model(X).reshape(-1)\n",
    "        \n",
    "        all_targets_train.extend(y.detach().cpu().numpy())\n",
    "        all_predictions_train.extend(y_pred.detach().cpu().numpy())\n",
    "        \n",
    "        loss = loss_function(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        train_loss /= len(train_dataloader)\n",
    "        rmse, r2 = evaluate(all_predictions_train, all_targets_train)\n",
    "        print(f\"After epoch {epoch+1}, train loss is {train_loss}, RMSE is {rmse}, and R2 is {r2}\")        \n",
    "    \n",
    "    test_loss = 0.0\n",
    "    all_targets_test = []\n",
    "    all_predictions_test = []\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for _, (X, y) in enumerate(test_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X).reshape(-1)\n",
    "            \n",
    "            all_targets_test.extend(y.cpu().numpy())\n",
    "            all_predictions_test.extend(y_pred.cpu().numpy())\n",
    "            \n",
    "            loss = loss_function(y_pred, y)\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        test_loss /= len(test_dataloader)\n",
    "        rmse, r2 = evaluate(all_predictions_test, all_targets_test)\n",
    "        print(f\"After epoch {epoch+1}, test loss is {test_loss}, RMSE is {rmse}, and R2 is {r2}\")\n",
    "        print(\"------------------------------------\")"
   ],
   "id": "67bd8e3a2a866fe0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 20, train loss is 3633.9680859375, RMSE is 60.28240203857422, and R2 is -14.988730838359128\n",
      "After epoch 20, test loss is 3366.7598702566966, RMSE is 58.19843292236328, and R2 is -13.053189984404723\n",
      "------------------------------------\n",
      "After epoch 40, train loss is 942.3897680664063, RMSE is 30.698368072509766, and R2 is -3.1463259050342938\n",
      "After epoch 40, test loss is 850.4998343331473, RMSE is 29.346771240234375, and R2 is -2.5733293895326086\n",
      "------------------------------------\n",
      "After epoch 60, train loss is 57.30001525878906, RMSE is 7.569677352905273, and R2 is 0.74789142854219\n",
      "After epoch 60, test loss is 56.03723308018276, RMSE is 7.746601581573486, and R2 is 0.7510140942795168\n",
      "------------------------------------\n",
      "After epoch 80, train loss is 19.042268142700195, RMSE is 4.363744735717773, and R2 is 0.9162178381448822\n",
      "After epoch 80, test loss is 23.298622948782786, RMSE is 5.015213966369629, and R2 is 0.8956406652171527\n",
      "------------------------------------\n",
      "After epoch 100, train loss is 14.315667114257813, RMSE is 3.7836050987243652, and R2 is 0.9370139349288377\n",
      "After epoch 100, test loss is 18.721043722970144, RMSE is 4.471832752227783, and R2 is 0.9170295363176115\n",
      "------------------------------------\n",
      "After epoch 120, train loss is 12.353703002929688, RMSE is 3.5147836208343506, and R2 is 0.945646183836363\n",
      "After epoch 120, test loss is 16.694689205714635, RMSE is 4.201701641082764, and R2 is 0.9267508251307381\n",
      "------------------------------------\n",
      "After epoch 140, train loss is 11.699654121398925, RMSE is 3.420475721359253, and R2 is 0.9485238681843873\n",
      "After epoch 140, test loss is 15.901524816240583, RMSE is 4.085078716278076, and R2 is 0.9307606184982069\n",
      "------------------------------------\n",
      "After epoch 160, train loss is 11.505978050231933, RMSE is 3.3920462131500244, and R2 is 0.9493760044745078\n",
      "After epoch 160, test loss is 15.56118665422712, RMSE is 4.032224178314209, and R2 is 0.9325407275633498\n",
      "------------------------------------\n",
      "After epoch 180, train loss is 11.442813453674317, RMSE is 3.382722854614258, and R2 is 0.9496539156080781\n",
      "After epoch 180, test loss is 15.386415754045759, RMSE is 4.004500389099121, and R2 is 0.9334651656978413\n",
      "------------------------------------\n",
      "After epoch 200, train loss is 11.415186862945557, RMSE is 3.3786370754241943, and R2 is 0.9497754660945825\n",
      "After epoch 200, test loss is 15.291506903512138, RMSE is 3.9889767169952393, and R2 is 0.933980015975072\n",
      "------------------------------------\n",
      "After epoch 220, train loss is 11.397579097747803, RMSE is 3.3760299682617188, and R2 is 0.9498529383510598\n",
      "After epoch 220, test loss is 15.238560812813896, RMSE is 3.9798262119293213, and R2 is 0.9342825679845204\n",
      "------------------------------------\n",
      "After epoch 240, train loss is 11.381632652282715, RMSE is 3.3736677169799805, and R2 is 0.949923099074881\n",
      "After epoch 240, test loss is 15.20380197252546, RMSE is 3.9734535217285156, and R2 is 0.9344928617400253\n",
      "------------------------------------\n",
      "After epoch 260, train loss is 11.361115570068359, RMSE is 3.3706254959106445, and R2 is 0.9500133695970536\n",
      "After epoch 260, test loss is 15.174370084490095, RMSE is 3.9677040576934814, and R2 is 0.9346822946046515\n",
      "------------------------------------\n",
      "After epoch 280, train loss is 11.328202953338623, RMSE is 3.365739583969116, and R2 is 0.9501581788789861\n",
      "After epoch 280, test loss is 15.143183435712542, RMSE is 3.9612205028533936, and R2 is 0.9348955913372371\n",
      "------------------------------------\n",
      "After epoch 300, train loss is 11.280501728057862, RMSE is 3.3586456775665283, and R2 is 0.9503680543306385\n",
      "After epoch 300, test loss is 15.11625303540911, RMSE is 3.955197811126709, and R2 is 0.9350934108591858\n",
      "------------------------------------\n",
      "After epoch 320, train loss is 11.217649784088135, RMSE is 3.349275827407837, and R2 is 0.9506445902689119\n",
      "After epoch 320, test loss is 15.09614304133824, RMSE is 3.9496042728424072, and R2 is 0.9352768624489112\n",
      "------------------------------------\n",
      "After epoch 340, train loss is 11.141168251037598, RMSE is 3.337839126586914, and R2 is 0.950981094207319\n",
      "After epoch 340, test loss is 15.08226980481829, RMSE is 3.9441258907318115, and R2 is 0.9354562952504447\n",
      "------------------------------------\n",
      "After epoch 360, train loss is 11.059361095428466, RMSE is 3.325561761856079, and R2 is 0.9513410294419152\n",
      "After epoch 360, test loss is 15.072489874703544, RMSE is 3.93900990486145, and R2 is 0.9356236238596561\n",
      "------------------------------------\n",
      "After epoch 380, train loss is 10.969716415405273, RMSE is 3.312056303024292, and R2 is 0.9517354476066748\n",
      "After epoch 380, test loss is 15.063611030578613, RMSE is 3.9335033893585205, and R2 is 0.9358034884319559\n",
      "------------------------------------\n",
      "After epoch 400, train loss is 10.874913196563721, RMSE is 3.297713279724121, and R2 is 0.9521525628254613\n",
      "After epoch 400, test loss is 15.06096703665597, RMSE is 3.928710460662842, and R2 is 0.9359598344264055\n",
      "------------------------------------\n",
      "After epoch 420, train loss is 10.76928035736084, RMSE is 3.2816579341888428, and R2 is 0.9526173263149738\n",
      "After epoch 420, test loss is 15.08253996712821, RMSE is 3.926849842071533, and R2 is 0.936020483463992\n",
      "------------------------------------\n",
      "After epoch 440, train loss is 10.66398956298828, RMSE is 3.2655763626098633, and R2 is 0.953080584380968\n",
      "After epoch 440, test loss is 15.11324065072196, RMSE is 3.926638126373291, and R2 is 0.9360273805136738\n",
      "------------------------------------\n",
      "After epoch 460, train loss is 10.568891963958741, RMSE is 3.250983238220215, and R2 is 0.9534989947045154\n",
      "After epoch 460, test loss is 15.146944318498884, RMSE is 3.9276340007781982, and R2 is 0.9359949223513624\n",
      "------------------------------------\n",
      "After epoch 480, train loss is 10.483240451812744, RMSE is 3.237783432006836, and R2 is 0.9538758437504486\n",
      "After epoch 480, test loss is 15.180661473955427, RMSE is 3.9285125732421875, and R2 is 0.9359662870091754\n",
      "------------------------------------\n",
      "After epoch 500, train loss is 10.406156368255616, RMSE is 3.2258572578430176, and R2 is 0.9542149984394164\n",
      "After epoch 500, test loss is 15.21897520337786, RMSE is 3.930508852005005, and R2 is 0.9359011978699925\n",
      "------------------------------------\n",
      "After epoch 520, train loss is 10.33398603439331, RMSE is 3.2146520614624023, and R2 is 0.9545325333071759\n",
      "After epoch 520, test loss is 15.263097354343959, RMSE is 3.9336299896240234, and R2 is 0.9357993554922068\n",
      "------------------------------------\n",
      "After epoch 540, train loss is 10.262199211120606, RMSE is 3.2034666538238525, and R2 is 0.9548483819211347\n",
      "After epoch 540, test loss is 15.30762413569859, RMSE is 3.9373836517333984, and R2 is 0.9356767717827945\n",
      "------------------------------------\n",
      "After epoch 560, train loss is 10.193909168243408, RMSE is 3.1927902698516846, and R2 is 0.9551488441175189\n",
      "After epoch 560, test loss is 15.353885105678014, RMSE is 3.9414680004119873, and R2 is 0.9355432510273165\n",
      "------------------------------------\n",
      "After epoch 580, train loss is 10.130425834655762, RMSE is 3.182832956314087, and R2 is 0.955428158010856\n",
      "After epoch 580, test loss is 15.393831389290947, RMSE is 3.944925308227539, and R2 is 0.9354301202553823\n",
      "------------------------------------\n",
      "After epoch 600, train loss is 10.069921760559081, RMSE is 3.173313856124878, and R2 is 0.9556943633828142\n",
      "After epoch 600, test loss is 15.435083525521415, RMSE is 3.9483389854431152, and R2 is 0.9353183347222194\n",
      "------------------------------------\n",
      "After epoch 620, train loss is 10.011888790130616, RMSE is 3.164156913757324, and R2 is 0.9559496968274125\n",
      "After epoch 620, test loss is 15.479681968688965, RMSE is 3.9525530338287354, and R2 is 0.9351801822746707\n",
      "------------------------------------\n",
      "After epoch 640, train loss is 9.9567804145813, RMSE is 3.1554367542266846, and R2 is 0.9561921630252032\n",
      "After epoch 640, test loss is 15.525748525347028, RMSE is 3.9569036960601807, and R2 is 0.9350374079315061\n",
      "------------------------------------\n",
      "After epoch 660, train loss is 9.903791027069092, RMSE is 3.147028923034668, and R2 is 0.9564253052879892\n",
      "After epoch 660, test loss is 15.570100784301758, RMSE is 3.9611458778381348, and R2 is 0.9348980434737492\n",
      "------------------------------------\n",
      "After epoch 680, train loss is 9.852797966003418, RMSE is 3.1389167308807373, and R2 is 0.9566496648076138\n",
      "After epoch 680, test loss is 15.611583300999232, RMSE is 3.9651811122894287, and R2 is 0.9347653381689554\n",
      "------------------------------------\n",
      "After epoch 700, train loss is 9.802851791381835, RMSE is 3.130950689315796, and R2 is 0.9568694179129841\n",
      "After epoch 700, test loss is 15.650803702218193, RMSE is 3.9691402912139893, and R2 is 0.9346349999080461\n",
      "------------------------------------\n",
      "After epoch 720, train loss is 9.755137481689452, RMSE is 3.123321533203125, and R2 is 0.9570793513800957\n",
      "After epoch 720, test loss is 15.693878310067314, RMSE is 3.9735844135284424, and R2 is 0.9344885493870354\n",
      "------------------------------------\n",
      "After epoch 740, train loss is 9.70888900756836, RMSE is 3.1159090995788574, and R2 is 0.9572828354950956\n",
      "After epoch 740, test loss is 15.738086427961077, RMSE is 3.978090286254883, and R2 is 0.9343398816591132\n",
      "------------------------------------\n",
      "After epoch 760, train loss is 9.663738842010497, RMSE is 3.1086554527282715, and R2 is 0.9574814870783042\n",
      "After epoch 760, test loss is 15.780009405953544, RMSE is 3.982262134552002, and R2 is 0.9342020999605676\n",
      "------------------------------------\n",
      "After epoch 780, train loss is 9.620174350738525, RMSE is 3.1016407012939453, and R2 is 0.9576731617809708\n",
      "After epoch 780, test loss is 15.82447065625872, RMSE is 3.986741542816162, and R2 is 0.9340539872432014\n",
      "------------------------------------\n",
      "After epoch 800, train loss is 9.576865348815918, RMSE is 3.094650983810425, and R2 is 0.957863712612403\n",
      "After epoch 800, test loss is 15.87158135005406, RMSE is 3.991609573364258, and R2 is 0.9338928380715806\n",
      "------------------------------------\n",
      "After epoch 820, train loss is 9.534738540649414, RMSE is 3.0878372192382812, and R2 is 0.9580490624026311\n",
      "After epoch 820, test loss is 15.91589982169015, RMSE is 3.9960508346557617, and R2 is 0.9337456538528356\n",
      "------------------------------------\n",
      "After epoch 840, train loss is 9.493729667663574, RMSE is 3.0811896324157715, and R2 is 0.9582294935486052\n",
      "After epoch 840, test loss is 15.95990766797747, RMSE is 4.000406265258789, and R2 is 0.933601152058433\n",
      "------------------------------------\n",
      "After epoch 860, train loss is 9.455724010467529, RMSE is 3.0750160217285156, and R2 is 0.9583967099966417\n",
      "After epoch 860, test loss is 16.001192229134695, RMSE is 4.004439830780029, and R2 is 0.9334671808458257\n",
      "------------------------------------\n",
      "After epoch 880, train loss is 9.419423351287842, RMSE is 3.0691077709198, and R2 is 0.9585564260360406\n",
      "After epoch 880, test loss is 16.039653096880233, RMSE is 4.00831937789917, and R2 is 0.9333382057464279\n",
      "------------------------------------\n",
      "After epoch 900, train loss is 9.382645664215088, RMSE is 3.0631103515625, and R2 is 0.9587182411519226\n",
      "After epoch 900, test loss is 16.073349952697754, RMSE is 4.011710166931152, and R2 is 0.9332253726920183\n",
      "------------------------------------\n",
      "After epoch 920, train loss is 9.346054058074952, RMSE is 3.05713152885437, and R2 is 0.9588792363875411\n",
      "After epoch 920, test loss is 16.10951723371233, RMSE is 4.015449523925781, and R2 is 0.9331008328785779\n",
      "------------------------------------\n",
      "After epoch 940, train loss is 9.312215919494628, RMSE is 3.0515923500061035, and R2 is 0.9590281175536863\n",
      "After epoch 940, test loss is 16.154210771833146, RMSE is 4.019853591918945, and R2 is 0.9329540019807925\n",
      "------------------------------------\n",
      "After epoch 960, train loss is 9.279097938537598, RMSE is 3.04616117477417, and R2 is 0.9591738296403959\n",
      "After epoch 960, test loss is 16.19255188533238, RMSE is 4.023408889770508, and R2 is 0.9328353517233915\n",
      "------------------------------------\n",
      "After epoch 980, train loss is 9.247308864593506, RMSE is 3.0409388542175293, and R2 is 0.9593136954404161\n",
      "After epoch 980, test loss is 16.232244764055526, RMSE is 4.027144908905029, and R2 is 0.9327105695002511\n",
      "------------------------------------\n",
      "After epoch 1000, train loss is 9.217695198059083, RMSE is 3.0360658168792725, and R2 is 0.959443989659662\n",
      "After epoch 1000, test loss is 16.27349717276437, RMSE is 4.031020641326904, and R2 is 0.9325809928799678\n",
      "------------------------------------\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
